# simple_network
Простая нейронная сеть для обучения.

## Описание
В данном репозитории хранится модель классической нейронной сети.
Модель полносвязная, со смещением. 
Представить модель можно следующим изображением.
![Модель сети](https://qph.fs.quoracdn.net/main-qimg-bf5a21006f36c6653a586b06da1a04f2.webp)

Нейроны с +1 это константные смещения.

## Как с этим работать
Для начала, необходимо создать набор слоев, в котором обязательно должен присутствовать входной и выходной.

    layers = [Layer(n_neurons=8, type="in"),
              Layer(n_neurons=8, type="hidden", f_activation=sigmoid),
              Layer(n_neurons=8, type='out', f_activation=sigmoid)]

Данная слои позволяют создать сеть из 3 слоев, у которых на каждом слою по 3 нейрона. 
У входного слоя, не должно быть функции активации.

    net = Network(layers)
    solver = BackPropagation(net)
    
Таким образом, определяется сеть и выбирается алгоритм оптимизации. 
Пока что реализован, только алгоритм обратного распространения.

    solver.fit(X, y, n_epoch=100)

Для тренировки сети необходимо передать в функцию fit массивы numpy. 
Алгоритмы работают только с этим типом данных. 
Также, необходимо указать количество эпох. 
За одну эпоху алгоритм оптимизации проходит через все данные один раз.

    solver.predict(X)

Для предсказания с помощью модели, нужно использовать функцию predict  и передавать в нее __массив__ данных.
Даже если это всего один элемент.
    
    solver.get_loss()
    solver.get_weights()
    
Метод _get_loss()_ возвращает ошибку за каждую эпоху, визуализируя эти данные, можно увидеть, как быстро сходится алгоритм.
Метод _get_weights()_ возвращает обученные веса, которые далее можно сохранить.
Для загрузки весов, необходимо использовать метод _set_weights()_ у объекта класса Network.


## Примеры

В файле _odd_even_classificator.ipynb_ находится пример построения классификатора для четности числа, представленного в битовом виде. 
Этот раздел будет пополняться.
