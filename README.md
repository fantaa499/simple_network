# simple_network
Простая нейронная сеть для обучения.

## Описание
В данном репозитории хранится модель классической нейронной сети.
Модель полносвязная, со смещением. 
Представить модель можно следующим изображением.
![Модель сети](https://qph.fs.quoracdn.net/main-qimg-bf5a21006f36c6653a586b06da1a04f2.webp)

Нейроны с +1 это константные смещения.

## Как с этим работать
Для начала, необходимо создать набор слоев, в котором обязательно должен присутствовать входной и выходной для подсчета ошибки.

    layers = [Input(2),      # На вход вектор из двух координат x и y
              Dense(100),    # Скрытый слой, со 100 нейронами
              ReLu(),        # Функция активации, обеспечивающая нелинейность
              Dense(3),      # Выходной слой, показывает метку класса
              Softmax(),     # Слой для перевода непонятных едениц измерения в вероятности
              LossSoftmax()] # Слой для подсчета ошибки

На данный момент реализованы слои:
- Input входной
- Dense полносвязный
Функции активации:
- Relu 
- Sigmoid
- Tanh
Прочие:
- Softmax
- LossSoftamx
- LossMSE

 
    net = Network(layers)
    solver = BackPropagation(net)
    
Таким образом, определяется сеть и выбирается алгоритм оптимизации.
Пока что реализован, только алгоритм обратного распространения.

    solver.fit(X, y, n_epoch=100, l_rate=1, l_rate_decay_n_epoch=10000, display=True)

Для тренировки сети необходимо передать в функцию fit массивы numpy. 
Алгоритмы работают только с этим типом данных. 
Также, необходимо указать количество эпох.
Возможно выбрать:
-l_rate
-l_rate_decay_n_epoch как часто происходит уменьшение l_rate в l_rate_decay раз
-display true/false отображать информацию об обучении или нет
-l_rate_decay во сколько раз уменьшить l_rate
-batch_size  размер батча, если не указано, то на обучение передаются все данные

    solver.predict(X)

Для предсказания с помощью модели, нужно использовать функцию predict  и передавать в нее __массив__ данных.
Даже если это всего один элемент.
    
    solver.get_loss()
    solver.get_weights()
    
Метод _get_loss()_ возвращает ошибку за каждую эпоху, визуализируя эти данные, можно увидеть, как быстро сходится алгоритм.
Метод _get_weights()_ возвращает обученные веса, которые далее можно сохранить.
Для загрузки весов, необходимо использовать метод _set_weights()_ у объекта класса Network.


## Примеры

В файле [_odd_even_classificator.ipynb_](https://github.com/fantaa499/simple_network/blob/master/odd_even_classificator.ipynb) находится пример построения классификатора для четности числа, представленного в битовом виде. 

В файле [_two_dim_color_points.ipynb_](https://github.com/fantaa499/simple_network/blob/master/two_dim_color_points.ipynb) находится пример построения классификатора для случаной сгенерированных точек.

В файле [_MNIST_classificator.ipynb_](https://github.com/fantaa499/simple_network/blob/master/MNIST_classificator.ipynb) находится пример построения классификатора для MNIST.

В файле [_autoencoder.ipynb_](https://github.com/fantaa499/simple_network/blob/master/autoencoder_not_working.ipynb) находится пример построения автоенкодера для MNIST. В процессе...




